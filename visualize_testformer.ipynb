{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import os\n",
                "# Ensure the root directory is in python path so we can import 'model' and 'layers'\n",
                "sys.path.append(os.path.abspath('.'))\n",
                "from model.Testformer import Model\n",
                "\n",
                "try:\n",
                "    from torchsummary import summary\n",
                "except ImportError:\n",
                "    print(\"torchsummary not found. Please install it using `pip install torchsummary`\")\n",
                "\n",
                "try:\n",
                "    from torchinfo import summary as summary_info\n",
                "except ImportError:\n",
                "    print(\"torchinfo not found (optional).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Config loaded.\n"
                    ]
                }
            ],
            "source": [
                "class Config:\n",
                "    \"\"\"\n",
                "    Configuration class mocking the arguments normally passed via command line.\n",
                "    Values are taken from the DEBUG run arguments.\n",
                "    \"\"\"\n",
                "    def __init__(self):\n",
                "        self.model_id = 'ETTh1_96_96'\n",
                "        self.model = 'Testformer'\n",
                "        self.data = 'ETTh1'\n",
                "        self.features = 'M'\n",
                "        self.seq_len = 96\n",
                "        self.label_len = 48\n",
                "        self.pred_len = 96\n",
                "        self.enc_in = 7\n",
                "        self.dec_in = 7\n",
                "        self.c_out = 7\n",
                "        self.d_model = 256\n",
                "        self.n_heads = 8\n",
                "        self.e_layers = 2\n",
                "        self.d_layers = 1\n",
                "        self.d_ff = 256\n",
                "        self.moving_avg = 25\n",
                "        self.factor = 1\n",
                "        self.distil = True\n",
                "        self.dropout = 0.1\n",
                "        self.embed = 'timeF'\n",
                "        self.activation = 'gelu'\n",
                "        self.output_attention = False\n",
                "        self.do_predict = False\n",
                "        self.freq = 'h'\n",
                "        self.class_strategy = 'projection'\n",
                "        self.use_gpu = torch.cuda.is_available()\n",
                "        self.use_channel_period_flex = True  # Assuming default True if not specified, or False based on code\n",
                "\n",
                "config = Config()\n",
                "print(\"Config loaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model moved to GPU.\n",
                        "Model(\n",
                        "  (decomp): Decomp(\n",
                        "    (ema): EMA()\n",
                        "  )\n",
                        "  (normlizer): Normalize()\n",
                        "  (trend_net): TrendFlow(\n",
                        "    (layer1): Sequential(\n",
                        "      (0): Linear(in_features=96, out_features=1024, bias=True)\n",
                        "      (1): GELU(approximate='none')\n",
                        "      (2): Dropout(p=0.1, inplace=False)\n",
                        "      (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
                        "    )\n",
                        "    (layer2): Sequential(\n",
                        "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
                        "      (1): GELU(approximate='none')\n",
                        "      (2): Dropout(p=0.1, inplace=False)\n",
                        "      (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
                        "    )\n",
                        "    (head): Linear(in_features=1024, out_features=256, bias=True)\n",
                        "  )\n",
                        "  (season_net): SeasonFlow(\n",
                        "    (enc_embedding): DataEmbedding_inverted(\n",
                        "      (value_embedding): Linear(in_features=96, out_features=256, bias=True)\n",
                        "      (dropout): Dropout(p=0.1, inplace=False)\n",
                        "    )\n",
                        "    (data_embedding): DataEmbedding(\n",
                        "      (value_embedding): TokenEmbedding(\n",
                        "        (tokenConv): Conv1d(7, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
                        "      )\n",
                        "      (position_embedding): PositionalEmbedding()\n",
                        "      (temporal_embedding): TimeFeatureEmbedding(\n",
                        "        (embed): Linear(in_features=4, out_features=256, bias=False)\n",
                        "      )\n",
                        "      (dropout): Dropout(p=0.1, inplace=False)\n",
                        "    )\n",
                        "    (mul_embedding): MultiResSeasonalEmbedding(\n",
                        "      (fusion_layer): Sequential(\n",
                        "        (0): Linear(in_features=768, out_features=256, bias=True)\n",
                        "        (1): GELU(approximate='none')\n",
                        "        (2): Dropout(p=0.1, inplace=False)\n",
                        "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
                        "      )\n",
                        "    )\n",
                        "    (mask_generator): Mahalanobis_mask()\n",
                        "    (encoder): Encoder(\n",
                        "      (attn_layers): ModuleList(\n",
                        "        (0-1): 2 x EncoderLayer(\n",
                        "          (attention): AttentionLayer(\n",
                        "            (inner_attention): FullAttention(\n",
                        "              (dropout): Dropout(p=0.1, inplace=False)\n",
                        "            )\n",
                        "            (query_projection): Linear(in_features=256, out_features=256, bias=True)\n",
                        "            (key_projection): Linear(in_features=256, out_features=256, bias=True)\n",
                        "            (value_projection): Linear(in_features=256, out_features=256, bias=True)\n",
                        "            (out_projection): Linear(in_features=256, out_features=256, bias=True)\n",
                        "          )\n",
                        "          (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
                        "          (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
                        "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
                        "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
                        "          (dropout): Dropout(p=0.1, inplace=False)\n",
                        "        )\n",
                        "      )\n",
                        "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
                        "    )\n",
                        "    (projector): Linear(in_features=256, out_features=96, bias=True)\n",
                        "  )\n",
                        "  (mask_generator): Mahalanobis_mask()\n",
                        "  (projector): Sequential(\n",
                        "    (0): Linear(in_features=256, out_features=384, bias=True)\n",
                        "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
                        "    (2): GELU(approximate='none')\n",
                        "    (3): Linear(in_features=384, out_features=192, bias=True)\n",
                        "    (4): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
                        "    (5): GELU(approximate='none')\n",
                        "    (6): Linear(in_features=192, out_features=96, bias=True)\n",
                        "    (7): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
                        "    (8): Linear(in_features=96, out_features=96, bias=True)\n",
                        "  )\n",
                        "  (interactive_proj): DecompInteractionProjector(\n",
                        "    (fusion): FiLMFusion_BCD(\n",
                        "      (gamma_net): Sequential(\n",
                        "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
                        "        (1): GELU(approximate='none')\n",
                        "        (2): Linear(in_features=512, out_features=256, bias=True)\n",
                        "      )\n",
                        "      (beta_net): Sequential(\n",
                        "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
                        "        (1): GELU(approximate='none')\n",
                        "        (2): Linear(in_features=512, out_features=256, bias=True)\n",
                        "      )\n",
                        "      (drop): Dropout(p=0.1, inplace=False)\n",
                        "    )\n",
                        "    (projector): Sequential(\n",
                        "      (0): Linear(in_features=256, out_features=384, bias=True)\n",
                        "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
                        "      (2): GELU(approximate='none')\n",
                        "      (3): Linear(in_features=384, out_features=192, bias=True)\n",
                        "      (4): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
                        "      (5): GELU(approximate='none')\n",
                        "      (6): Linear(in_features=192, out_features=96, bias=True)\n",
                        "      (7): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
                        "      (8): Linear(in_features=96, out_features=96, bias=True)\n",
                        "    )\n",
                        "  )\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "# Instantiate the model\n",
                "model = Model(config)\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    model = model.cuda()\n",
                "    print(\"Model moved to GPU.\")\n",
                "else:\n",
                "    print(\"Model on CPU.\")\n",
                "\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Model Summary (torchsummary) ---\n",
                        "torchsummary failed: 'NoneType' object has no attribute 'size'\n"
                    ]
                }
            ],
            "source": [
                "# Visualize using torchsummary\n",
                "# Input shape expected by torchsummary is (Channels, Length) or similar, but it adds Batch dim automatically.\n",
                "# Testformer expects input x_enc: [Batch, Seq_Len, Enc_In]\n",
                "# So we pass (seq_len, enc_in)\n",
                "\n",
                "print(\"\\n--- Model Summary (torchsummary) ---\")\n",
                "try:\n",
                "    # Note: torchsummary's summary(model, input_size) creates a tensor of shape (Batch, *input_size)\n",
                "    # So passing (96, 7) creates [Batch, 96, 7], which matches x_enc shape.\n",
                "    summary(model, (config.seq_len, config.enc_in))\n",
                "except Exception as e:\n",
                "    print(f\"torchsummary failed: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Model Summary (torchinfo) ---\n",
                        "torchinfo execution failed: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Normalize: 1, Mahalanobis_mask: 1, Decomp: 1, EMA: 2, TrendFlow: 1, Sequential: 2, Linear: 3, GELU: 3, Dropout: 3, LayerNorm: 3, Sequential: 2, Linear: 3, GELU: 3, Dropout: 3, LayerNorm: 3, Linear: 2, DataEmbedding_inverted: 2, Linear: 3, Dropout: 3, Linear: 6, Linear: 6, Linear: 6, Dropout: 7]\n"
                    ]
                }
            ],
            "source": [
                "# Visualize using torchinfo (if available) - Provides more detailed layer info\n",
                "try:\n",
                "    batch_size = 32\n",
                "    print(\"\\n--- Model Summary (torchinfo) ---\")\n",
                "    # summary_info handles args more flexibly. passing input_size explicitly.\n",
                "    summary_info(model, input_size=(batch_size, config.seq_len, config.enc_in), \n",
                "                 col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"], \n",
                "                 verbose=1)\n",
                "except NameError:\n",
                "    pass\n",
                "except Exception as e:\n",
                "    print(f\"torchinfo execution failed: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
