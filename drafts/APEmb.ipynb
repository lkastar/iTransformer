{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21a90ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (48x96 and 48x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 311\u001b[39m\n\u001b[32m    308\u001b[39m pa_emb = PAEmbedding(c_in=\u001b[32m7\u001b[39m, seq_len=\u001b[32m96\u001b[39m, d_model=\u001b[32m128\u001b[39m, anchor_period=\u001b[32m48\u001b[39m)\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m out = \u001b[43mpa_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInput shape:\u001b[39m\u001b[33m\"\u001b[39m, x.shape)\n\u001b[32m    314\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput shape:\u001b[39m\u001b[33m\"\u001b[39m, out.shape) \u001b[38;5;66;03m# Should be [32, 7, 128]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/timeseries/iTransformer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/timeseries/iTransformer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 219\u001b[39m, in \u001b[36mPAEmbedding.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28mself\u001b[39m._weight_cache = {}\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Stream 3: Global Trend (全局趋势流)\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# 处理整个序列 T。Flex-Resize: Anchor(48) -> T\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# 这是一个巨大的低通滤波器\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m w_trend = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_flex_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# [d_model, T]\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# x: [B, T, C] -> permute -> [B, C, T]\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Linear: x @ w.T -> [B, C, d_model]\u001b[39;00m\n\u001b[32m    222\u001b[39m stream_trend_out = F.linear(x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m), w_trend, \u001b[38;5;28mself\u001b[39m.anchor_bias)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mPAEmbedding._get_flex_weight\u001b[39m\u001b[34m(self, target_len)\u001b[39m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._weight_cache[target_len]\n\u001b[32m    182\u001b[39m \u001b[38;5;66;03m# 调用 LightGTS 的核心 Flex-Resize\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# 注意: anchor_weight 是 [d_model, anchor_len]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m new_w = \u001b[43mresample_patchemb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43manchor_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28mself\u001b[39m._weight_cache[target_len] = new_w\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_w\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mresample_patchemb\u001b[39m\u001b[34m(old, new_patch_len)\u001b[39m\n\u001b[32m     47\u001b[39m resize_mat_pinv = torch.linalg.pinv(resize_mat.T) \u001b[38;5;66;03m# pseudo inverse\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 应用变换\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m resampled_kernels = \u001b[43mresize_mat_pinv\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_T\u001b[49m * math.sqrt(factor)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resampled_kernels.T\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (48x96 and 48x128)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.fft as fft\n",
    "\n",
    "# 引入用户提供的组件 (假设在同一路径或已定义)\n",
    "# from resample_emb import resample_patchemb \n",
    "\n",
    "# ==========================================\n",
    "# 1. 核心工具函数 (基于用户提供的代码)\n",
    "# ==========================================\n",
    "\n",
    "def resample_patchemb(old: torch.Tensor, new_patch_len: int):\n",
    "    \"\"\"\n",
    "    LightGTS Flex-Resize 核心逻辑: 利用伪逆动态调整权重矩阵形状\n",
    "    Input: old [d_model, anchor_len] (注意: nn.Linear.weight 是转置存储的)\n",
    "    Output: new [d_model, new_patch_len]\n",
    "    \"\"\"\n",
    "    assert old.dim() == 2, \"输入张量应为2D (d_model, patch_size)\"\n",
    "    if old.size(1) == new_patch_len:\n",
    "        return old\n",
    "\n",
    "    # 这里的逻辑主要是转置处理，适应 SVD/Pinv 的维度要求\n",
    "    old_T = old.T # [anchor_len, d_model]\n",
    "    old_shape = old_T.size(0)\n",
    "    factor = new_patch_len / old_shape\n",
    "    \n",
    "    # 定义辅助函数：批量resize (用于构造变换矩阵)\n",
    "    def resize_fn(x_tensor, new_shape):\n",
    "        # [1, 1, L] -> interpolate -> [1, 1, New_L]\n",
    "        return F.interpolate(x_tensor.unsqueeze(0).unsqueeze(0), size=new_shape, mode='linear', align_corners=False).squeeze(0).squeeze(0)\n",
    "\n",
    "    # 构造缩放矩阵 A\n",
    "    basis_vectors = torch.eye(old_shape, dtype=torch.float32, device=old.device) # [L, L]\n",
    "    # Resize 每一行基向量\n",
    "    # 这里为了效率，其实可以预计算，但在动态周期下需实时计算\n",
    "    # [L, New_L]\n",
    "    resize_mat_list = [resize_fn(basis_vectors[i], new_patch_len) for i in range(old_shape)]\n",
    "    resize_mat = torch.stack(resize_mat_list) \n",
    "    \n",
    "    # 计算伪逆: theta' = delta^-1 * (A)^+ * theta\n",
    "    # resize_mat corresponds to A.T in the paper's notation xA\n",
    "    # We need to map weight from P to P'. \n",
    "    # paper: theta' = delta^-1 * (A)^+ * theta\n",
    "    \n",
    "    resize_mat_pinv = torch.linalg.pinv(resize_mat.T) # pseudo inverse\n",
    "    \n",
    "    # 应用变换\n",
    "    resampled_kernels = resize_mat_pinv @ old_T * math.sqrt(factor)\n",
    "\n",
    "    return resampled_kernels.T # 转回 [d_model, new_patch_len]\n",
    "\n",
    "def ACF_for_Period_Per_Channel(x, k=2, min_period=4):\n",
    "    \"\"\"\n",
    "    用户提供的 ACF 周期提取函数\n",
    "    x: [B, T, C] -> 返回 [C, k] (每个通道的 Top-k 周期)\n",
    "    \"\"\"\n",
    "    B, T, C = x.shape\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    x_centered = x - x_mean\n",
    "\n",
    "    # FFT 计算自相关\n",
    "    n_fft = 1 << (2 * T - 1).bit_length()\n",
    "    xf = torch.fft.rfft(x_centered, n=n_fft, dim=1)\n",
    "    power_spectrum = xf * torch.conj(xf)\n",
    "    acf = torch.fft.irfft(power_spectrum, n=n_fft, dim=1)\n",
    "    acf = acf[:, :T, :]\n",
    "    \n",
    "    # 聚合 Batch 维度\n",
    "    avg_acf = acf.mean(dim=0) # [T, C]\n",
    "    \n",
    "    # 掩码处理\n",
    "    avg_acf[:min_period, :] = -float('inf')\n",
    "    \n",
    "    prev_lag = torch.roll(avg_acf, 1, dims=0)\n",
    "    next_lag = torch.roll(avg_acf, -1, dims=0)\n",
    "    prev_lag[0, :] = -float('inf')\n",
    "    next_lag[-1, :] = -float('inf')\n",
    "    \n",
    "    is_peak = (avg_acf > prev_lag) & (avg_acf > next_lag) & (avg_acf > 0)\n",
    "    masked_acf = avg_acf.clone()\n",
    "    masked_acf[~is_peak] = -float('inf')\n",
    "    \n",
    "    # 提取 Top-K\n",
    "    top_vals, top_inds = torch.topk(masked_acf, k, dim=0)\n",
    "    \n",
    "    return top_inds.t() # [C, k]\n",
    "\n",
    "# ==========================================\n",
    "# 2. 核心模块: Attentive Aggregator\n",
    "# ==========================================\n",
    "\n",
    "class AttentiveAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    替代简单的“同步平均”。\n",
    "    利用 Attention 机制，根据 Query (Last Patch) 动态聚合所有历史周期的 Patch。\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=n_heads, batch_first=True, dropout=dropout)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, patches):\n",
    "        \"\"\"\n",
    "        patches: [Batch, Num_Patches, d_model]\n",
    "        return: [Batch, d_model] (聚合后的单个 Token)\n",
    "        \"\"\"\n",
    "        # Query: 取最后一个 Patch (最近的时间窗口)，代表当前的相位/模式\n",
    "        # [Batch, 1, d_model]\n",
    "        query = patches[:, -1:, :] \n",
    "        \n",
    "        # Key/Value: 所有 Patch\n",
    "        # [Batch, Num_Patches, d_model]\n",
    "        key_value = patches\n",
    "        \n",
    "        # Attention\n",
    "        attn_out, _ = self.attn(query, key_value, key_value)\n",
    "        \n",
    "        # Residual + Norm\n",
    "        out = self.norm(query + self.dropout(attn_out))\n",
    "        \n",
    "        return out.squeeze(1)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 主架构: PAEmbedding\n",
    "# ==========================================\n",
    "\n",
    "class PAEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, d_model, anchor_period=48, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Period-Adaptive Embedding Layer\n",
    "        \n",
    "        Args:\n",
    "            c_in: 变量数量 (Channels)\n",
    "            seq_len: 输入序列长度 (Lookback window)\n",
    "            d_model: 隐层维度\n",
    "            anchor_period: LightGTS Flex-Resize 的参考锚点长度 (Default: 48)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.c_in = c_in\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.anchor_period = anchor_period\n",
    "        \n",
    "        # --- 1. Anchor Weights (参数库) ---\n",
    "        # 这是一个形状为 [d_model, anchor_period] 的基准权重\n",
    "        # 所有的 Period Projection 都会从这个权重动态变形而来，实现参数共享\n",
    "        self.anchor_weight = nn.Parameter(torch.randn(d_model, anchor_period))\n",
    "        self.anchor_bias = nn.Parameter(torch.zeros(d_model))\n",
    "        nn.init.xavier_uniform_(self.anchor_weight)\n",
    "\n",
    "        # --- 2. Aggregators (去噪聚合) ---\n",
    "        # Stream 1: 主周期聚合器\n",
    "        self.agg_p1 = AttentiveAggregator(d_model, dropout=dropout)\n",
    "        # Stream 2: 次周期聚合器\n",
    "        self.agg_p2 = AttentiveAggregator(d_model, dropout=dropout)\n",
    "        \n",
    "        # --- 3. Stream 3 (Global Trend) ---\n",
    "        # 全局趋势不需要聚合，直接是一个长切片 Flex-Resize 到 d_model\n",
    "        # 但我们仍然使用 Anchor 机制来生成这个巨大的投影层\n",
    "        \n",
    "        # --- 4. Stream Fusion (融合层) ---\n",
    "        # 融合 [Stream1, Stream2, Stream3] -> Final Token\n",
    "        # 输入维度: 3 * d_model -> 输出: d_model\n",
    "        self.fusion_layer = nn.Sequential(\n",
    "            nn.Linear(3 * d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        \n",
    "        # 缓存 (可选，用于加速)\n",
    "        self._weight_cache = {} \n",
    "\n",
    "    def _get_flex_weight(self, target_len):\n",
    "        \"\"\"获取适配 target_len 的权重，带简单的运行时缓存\"\"\"\n",
    "        if target_len in self._weight_cache:\n",
    "            return self._weight_cache[target_len]\n",
    "        \n",
    "        # 调用 LightGTS 的核心 Flex-Resize\n",
    "        # 注意: anchor_weight 是 [d_model, anchor_len]\n",
    "        new_w = resample_patchemb(self.anchor_weight, target_len)\n",
    "        self._weight_cache[target_len] = new_w\n",
    "        return new_w\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [Batch, Seq_Len, Channels]\n",
    "        Output: [Batch, Channels, d_model] -> 符合 iTransformer 的输入格式\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        # Step 1: 发现周期 (Per-Channel ACF)\n",
    "        # periods: [C, 2] -> 每个变量的两个显著周期\n",
    "        with torch.no_grad():\n",
    "            periods = ACF_for_Period_Per_Channel(x.permute(0, 2, 1), k=2) # permute to [B, C, T] for ACF func\n",
    "            # 限制周期范围，防止过小或过大导致数值不稳定\n",
    "            periods = torch.clamp(periods, min=4, max=T//2)\n",
    "        \n",
    "        # Step 2: 变量分组处理 (为了利用 Batch 计算，虽然每个变量周期不同)\n",
    "        # 在工程实现上，为了避免 Loop N 次 (太慢)，我们将变量按计算出的 Period 进行分组\n",
    "        # 但为了演示清晰，这里先展示逻辑循环，实际部署建议使用 Scatter/Gather 或 CUDA Kernel\n",
    "        \n",
    "        # 初始化三个流的输出容器\n",
    "        stream_p1_out = torch.zeros(B, C, self.d_model, device=x.device)\n",
    "        stream_p2_out = torch.zeros(B, C, self.d_model, device=x.device)\n",
    "        stream_trend_out = torch.zeros(B, C, self.d_model, device=x.device)\n",
    "        \n",
    "        # 清空权重缓存 (Dynamic graph issues)\n",
    "        self._weight_cache = {}\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Stream 3: Global Trend (全局趋势流)\n",
    "        # -------------------------------------------------------\n",
    "        # 处理整个序列 T。Flex-Resize: Anchor(48) -> T\n",
    "        # 这是一个巨大的低通滤波器\n",
    "        w_trend = self._get_flex_weight(T) # [d_model, T]\n",
    "        # x: [B, T, C] -> permute -> [B, C, T]\n",
    "        # Linear: x @ w.T -> [B, C, d_model]\n",
    "        stream_trend_out = F.linear(x.permute(0, 2, 1), w_trend, self.anchor_bias)\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Stream 1 & 2: Period Streams (周期流)\n",
    "        # -------------------------------------------------------\n",
    "        # 这里为了演示逻辑，我们对 Unique Period 进行循环 (比对 C 循环快得多)\n",
    "        # 因为现实中很多变量可能共享相同的周期 (如 24, 96)\n",
    "        \n",
    "        unique_periods = torch.unique(periods)\n",
    "        \n",
    "        for p in unique_periods:\n",
    "            p = p.item()\n",
    "            # 找到哪些 Channel 拥有这个周期 (作为 P1 或 P2)\n",
    "            # mask_p1: [C]\n",
    "            mask_p1 = (periods[:, 0] == p)\n",
    "            mask_p2 = (periods[:, 1] == p)\n",
    "            \n",
    "            if not (mask_p1.any() or mask_p2.any()):\n",
    "                continue\n",
    "                \n",
    "            # 获取适配该周期的权重\n",
    "            w_p = self._get_flex_weight(p) # [d_model, p]\n",
    "            \n",
    "            # 准备数据切片\n",
    "            # Unfold: [B, T, C] -> [B, Num_Patches, C, P]\n",
    "            # 仅选取需要的 Channel 以节省计算\n",
    "            # 这里简单起见，先对所有 Channel unfold，再 mask\n",
    "            # Stride = P (非重叠切片，LightGTS 逻辑)\n",
    "            patches = x.unfold(dimension=1, size=p, step=p) \n",
    "            # patches: [B, Num_Patches, C, P]\n",
    "            \n",
    "            # 投影 (Tokenization)\n",
    "            # [B, Num_Patches, C, P] @ [P, d_model] -> [B, Num_Patches, C, d_model]\n",
    "            # 这一步将物理数据映射到了语义空间\n",
    "            tokens = patches @ w_p.T \n",
    "            \n",
    "            # --- Stream 1 处理 ---\n",
    "            if mask_p1.any():\n",
    "                # 选出对应 Channel: [B, Num_Patches, N_subset, d_model]\n",
    "                tokens_subset = tokens[:, :, mask_p1, :]\n",
    "                # 变换维度以适应 Aggregator: [B * N_subset, Num_Patches, d_model]\n",
    "                b_sz, num_p, n_sub, d_m = tokens_subset.shape\n",
    "                tokens_flat = tokens_subset.permute(0, 2, 1, 3).reshape(-1, num_p, d_m)\n",
    "                \n",
    "                # 聚合 (Attention Aggregation)\n",
    "                agg_tokens = self.agg_p1(tokens_flat) # [B*N_subset, d_model]\n",
    "                agg_tokens = agg_tokens.reshape(b_sz, n_sub, d_m)\n",
    "                \n",
    "                # 填回结果\n",
    "                stream_p1_out[:, mask_p1, :] = agg_tokens\n",
    "\n",
    "            # --- Stream 2 处理 ---\n",
    "            if mask_p2.any():\n",
    "                tokens_subset = tokens[:, :, mask_p2, :]\n",
    "                b_sz, num_p, n_sub, d_m = tokens_subset.shape\n",
    "                tokens_flat = tokens_subset.permute(0, 2, 1, 3).reshape(-1, num_p, d_m)\n",
    "                \n",
    "                agg_tokens = self.agg_p2(tokens_flat)\n",
    "                agg_tokens = agg_tokens.reshape(b_sz, n_sub, d_m)\n",
    "                \n",
    "                stream_p2_out[:, mask_p2, :] = agg_tokens\n",
    "\n",
    "        # -------------------------------------------------------\n",
    "        # Fusion (融合)\n",
    "        # -------------------------------------------------------\n",
    "        # 此时我们有三个 [B, C, d_model] 的张量\n",
    "        \n",
    "        # 拼接\n",
    "        combined = torch.cat([stream_p1_out, stream_p2_out, stream_trend_out], dim=-1) # [B, C, 3*d_model]\n",
    "        \n",
    "        # 融合投影\n",
    "        variate_token = self.fusion_layer(combined) # [B, C, d_model]\n",
    "        \n",
    "        # 输出形状符合 iTransformer 的 Encoder 输入要求\n",
    "        # [Batch, Variates, d_model]\n",
    "        return variate_token\n",
    "\n",
    "# ==========================================\n",
    "# 4. 示例调用 (Example Usage)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 模拟数据: Batch=32, Lookback=96, Channels=7\n",
    "    x = torch.randn(32, 96, 7)\n",
    "    \n",
    "    # 实例化 PAEmbedding\n",
    "    # 使用 48 作为 Anchor，意味着模型学习的是一个长度为 48 的“标准周期模式”\n",
    "    pa_emb = PAEmbedding(c_in=7, seq_len=96, d_model=128, anchor_period=48)\n",
    "    \n",
    "    # 前向传播\n",
    "    out = pa_emb(x)\n",
    "    \n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Output shape:\", out.shape) # Should be [32, 7, 128]\n",
    "    print(\"PA-Embedding successfully processed multi-scale inputs into unified tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77bf6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([32, 7, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础工具组件\n",
    "# ==========================================\n",
    "\n",
    "def resample_patchemb(old_weight: torch.Tensor, new_patch_len: int):\n",
    "    \"\"\"\n",
    "    Flex-Resize: 调整权重矩阵形状 [d_model, old_len] -> [d_model, new_len]\n",
    "    \"\"\"\n",
    "    assert old_weight.dim() == 2\n",
    "    if old_weight.size(1) == new_patch_len:\n",
    "        return old_weight\n",
    "\n",
    "    old = old_weight.T # [old_len, d_model]\n",
    "    old_len = old.size(0)\n",
    "    factor = new_patch_len / old_len\n",
    "    \n",
    "    # 构造变换矩阵 (Interpolation Matrix)\n",
    "    basis_vectors = torch.eye(old_len, dtype=torch.float32, device=old.device)\n",
    "    # [1, 1, old, old] -> [1, 1, new, old] -> [new, old]\n",
    "    resize_mat = F.interpolate(\n",
    "        basis_vectors.unsqueeze(0).unsqueeze(0), \n",
    "        size=(new_patch_len, old_len), \n",
    "        mode='bilinear', \n",
    "        align_corners=False\n",
    "    ).squeeze(0).squeeze(0)\n",
    "    \n",
    "    # 计算伪逆: theta' = (A)^+ * theta * scale\n",
    "    resize_mat_pinv = torch.linalg.pinv(resize_mat.T) # [new, old]\n",
    "    resampled = resize_mat_pinv @ old * math.sqrt(factor)\n",
    "\n",
    "    return resampled.T # [d_model, new_len]\n",
    "\n",
    "def ACF_for_Period_Per_Channel(x, k=2, min_period=4):\n",
    "    \"\"\"\n",
    "    计算每个通道的 Top-K 周期\n",
    "    x: [B, T, C] -> Returns: [C, k]\n",
    "    \"\"\"\n",
    "    B, T, C = x.shape\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    x_centered = x - x_mean\n",
    "\n",
    "    n_fft = 1 << (2 * T - 1).bit_length()\n",
    "    xf = torch.fft.rfft(x_centered, n=n_fft, dim=1)\n",
    "    power_spectrum = xf * torch.conj(xf)\n",
    "    acf = torch.fft.irfft(power_spectrum, n=n_fft, dim=1)\n",
    "    acf = acf[:, :T, :]\n",
    "    avg_acf = acf.mean(dim=0) # [T, C]\n",
    "    \n",
    "    avg_acf[:min_period, :] = -float('inf')\n",
    "    \n",
    "    prev = torch.roll(avg_acf, 1, dims=0); prev[0, :] = -float('inf')\n",
    "    next_ = torch.roll(avg_acf, -1, dims=0); next_[-1, :] = -float('inf')\n",
    "    is_peak = (avg_acf > prev) & (avg_acf > next_) & (avg_acf > 0)\n",
    "    \n",
    "    masked_acf = avg_acf.clone()\n",
    "    masked_acf[~is_peak] = -float('inf')\n",
    "    \n",
    "    _, top_inds = torch.topk(masked_acf, k, dim=0)\n",
    "    return top_inds.t()\n",
    "\n",
    "# ==========================================\n",
    "# 2. 门控融合模块 (Gated Fusion)\n",
    "# ==========================================\n",
    "\n",
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        # 输入: P1, P2, Trend (拼接后 3*d_model)\n",
    "        # 输出: 3个权重系数\n",
    "        self.gate_net = nn.Sequential(\n",
    "            nn.Linear(3 * d_model, d_model),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(d_model, 3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, p1, p2, trend):\n",
    "        \"\"\"\n",
    "        p1, p2, trend: [B, C, d_model]\n",
    "        \"\"\"\n",
    "        # 拼接特征用于计算门控权重\n",
    "        concat_feat = torch.cat([p1, p2, trend], dim=-1) # [B, C, 3*d]\n",
    "        weights = self.gate_net(concat_feat) # [B, C, 3]\n",
    "        \n",
    "        # 拆分权重: w1, w2, w3 均为 [B, C, 1]\n",
    "        w1, w2, w3 = weights.unbind(dim=-1)\n",
    "        w1, w2, w3 = w1.unsqueeze(-1), w2.unsqueeze(-1), w3.unsqueeze(-1)\n",
    "        \n",
    "        # 加权融合\n",
    "        out = w1 * p1 + w2 * p2 + w3 * trend\n",
    "        return self.norm(out)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 主架构: PAEmbedding (Robust Ver.)\n",
    "# ==========================================\n",
    "\n",
    "class PAEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, seq_len, d_model, anchor_periods=[12, 24, 48, 96], dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.d_model = d_model\n",
    "        self.anchor_periods = sorted(anchor_periods)\n",
    "        \n",
    "        # --- Stream 3: Trend (保底机制) ---\n",
    "        # 【修改点1】完全独立的 Linear 层，不使用 Flex-Resize\n",
    "        # 这是 iTransformer 的原版 Embedding 方式，保留全序列信息\n",
    "        self.raw_projection = nn.Linear(seq_len, d_model)\n",
    "        \n",
    "        # --- Stream 1 & 2: Period (周期特征) ---\n",
    "        # 【修改点3】Bias 解耦，每个 Anchor 有独立的 Bias\n",
    "        self.anchor_weights = nn.ParameterDict()\n",
    "        self.anchor_biases = nn.ParameterDict()\n",
    "        \n",
    "        for p in self.anchor_periods:\n",
    "            w = nn.Parameter(torch.empty(d_model, p))\n",
    "            b = nn.Parameter(torch.zeros(d_model))\n",
    "            nn.init.xavier_uniform_(w)\n",
    "            self.anchor_weights[str(p)] = w\n",
    "            self.anchor_biases[str(p)] = b\n",
    "            \n",
    "        # --- Fusion ---\n",
    "        # 【修改点4】使用 Gated Fusion\n",
    "        self.fusion = GatedFusion(d_model)\n",
    "        \n",
    "        # Cache\n",
    "        self._weight_cache = {}\n",
    "\n",
    "    def _get_flex_params(self, target_len):\n",
    "        \"\"\"获取适配 target_len 的权重和偏置\"\"\"\n",
    "        if target_len in self._weight_cache:\n",
    "            return self._weight_cache[target_len]\n",
    "        \n",
    "        # 1. 找最近锚点\n",
    "        # 优化：增加对齐容忍度，避免微小差异导致的 resize\n",
    "        # 例如 target=23, anchor=24，resize 影响很小\n",
    "        source_p = min(self.anchor_periods, key=lambda x: abs(x - target_len))\n",
    "        \n",
    "        source_w = self.anchor_weights[str(source_p)]\n",
    "        source_b = self.anchor_biases[str(source_p)] # Bias 直接复用，不 resize\n",
    "        \n",
    "        # 2. Resize 权重\n",
    "        new_w = resample_patchemb(source_w, target_len)\n",
    "        \n",
    "        self._weight_cache[target_len] = (new_w, source_b)\n",
    "        return new_w, source_b\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [Batch, Seq_Len, Channels] (B, T, C)\n",
    "        Returns: [Batch, Channels, d_model]\n",
    "        \"\"\"\n",
    "        B, T, C = x.shape\n",
    "        self._weight_cache = {} # Clear cache\n",
    "        \n",
    "        # ---------------------------------------------------\n",
    "        # Stream 3: Trend Extraction (基准流)\n",
    "        # ---------------------------------------------------\n",
    "        # x.permute(0, 2, 1) -> [B, C, T]\n",
    "        # raw_projection -> [B, C, d_model]\n",
    "        # 这一步保证了即便 periodic stream 失效，模型表现也不会低于 iTransformer\n",
    "        stream_trend = self.raw_projection(x.permute(0, 2, 1))\n",
    "        \n",
    "        # ---------------------------------------------------\n",
    "        # Stream 1 & 2: Periodic Extraction (增强流)\n",
    "        # ---------------------------------------------------\n",
    "        # 初始化为 0，若没检测到周期则不贡献\n",
    "        stream_p1 = torch.zeros(B, C, self.d_model, device=x.device)\n",
    "        stream_p2 = torch.zeros(B, C, self.d_model, device=x.device)\n",
    "        \n",
    "        # 1. 计算周期\n",
    "        with torch.no_grad():\n",
    "            periods = ACF_for_Period_Per_Channel(x, k=2) \n",
    "            periods = torch.clamp(periods, min=4, max=T//2) # 限制范围\n",
    "            \n",
    "        unique_periods = torch.unique(periods)\n",
    "        \n",
    "        for p in unique_periods:\n",
    "            p_val = p.item()\n",
    "            mask_p1 = (periods[:, 0] == p_val)\n",
    "            mask_p2 = (periods[:, 1] == p_val)\n",
    "            \n",
    "            if not (mask_p1.any() or mask_p2.any()): continue\n",
    "            \n",
    "            # 获取动态参数\n",
    "            w_p, b_p = self._get_flex_params(p_val)\n",
    "            \n",
    "            # 切片与投影\n",
    "            combined_mask = mask_p1 | mask_p2\n",
    "            x_subset = x[:, :, combined_mask].permute(0, 2, 1) # [B, N_sub, T]\n",
    "            \n",
    "            # Unfold: [B, N_sub, Num_Patches, P]\n",
    "            patches = x_subset.unfold(dimension=2, size=p_val, step=p_val)\n",
    "            \n",
    "            # Tokenization: [B, N_sub, Num_Patches, d_model]\n",
    "            tokens = F.linear(patches, w_p, b_p)\n",
    "            \n",
    "            # 【修改点2】 Aggregation: 改用 Mean Pooling\n",
    "            # tokens.mean(dim=2) -> [B, N_sub, d_model]\n",
    "            # 相比 Attention，Mean Pooling 无需参数，训练更稳定\n",
    "            # 虽然牺牲了动态性，但配合 Gated Fusion 可以由 Trend 流弥补\n",
    "            agg_tokens = tokens.mean(dim=2)\n",
    "            \n",
    "            # 分发结果\n",
    "            if mask_p1.any():\n",
    "                # 寻找 mask_p1 在 combined_mask 中的索引\n",
    "                subset_indices = torch.where(combined_mask)[0]\n",
    "                p1_global_indices = torch.where(mask_p1)[0]\n",
    "                # isin 得到的是 bool mask，长度等于 subset 大小\n",
    "                rel_mask = torch.isin(subset_indices, p1_global_indices)\n",
    "                \n",
    "                stream_p1[:, mask_p1, :] = agg_tokens[:, rel_mask, :]\n",
    "                \n",
    "            if mask_p2.any():\n",
    "                subset_indices = torch.where(combined_mask)[0]\n",
    "                p2_global_indices = torch.where(mask_p2)[0]\n",
    "                rel_mask = torch.isin(subset_indices, p2_global_indices)\n",
    "                \n",
    "                stream_p2[:, mask_p2, :] = agg_tokens[:, rel_mask, :]\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # Final Fusion\n",
    "        # ---------------------------------------------------\n",
    "        # 动态加权融合\n",
    "        variate_token = self.fusion(stream_p1, stream_p2, stream_trend)\n",
    "        \n",
    "        return variate_token\n",
    "\n",
    "# Test\n",
    "if __name__ == \"__main__\":\n",
    "    model = PAEmbedding(c_in=7, seq_len=96, d_model=128)\n",
    "    x = torch.randn(32, 96, 7)\n",
    "    out = model(x)\n",
    "    print(\"Output:\", out.shape) # [32, 7, 128]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
